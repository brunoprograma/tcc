{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pureza_topicos_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ribeiroti/tcc/blob/master/pureza_topicos_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KETBE6jzXOxw",
        "colab_type": "text"
      },
      "source": [
        "#Implementação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0KqOXrSTSA1",
        "colab_type": "text"
      },
      "source": [
        "## Dados dos datasets\n",
        "\n",
        "Dataset | Query | Dataset | Rel | % Rel\n",
        "--- | --- | --- | --- | ---\n",
        "Hall | Defect prediction | 8911 | 104 | 1.17\n",
        "Radjenovic | Defect prediction metrics | 6000 | 48 | 0.80\n",
        "Kitchenham | Literature review | 1704 | 45 | 2.64\n",
        "Wahono | Defect prediction | 7002 | 62 | 0.88"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj3DFLWBfZgK",
        "colab_type": "text"
      },
      "source": [
        "## Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-dXiNo5Y8-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import datetime\n",
        "from collections import OrderedDict\n",
        "from random import seed\n",
        "from random import randint\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Python version\")\n",
        "print (sys.version)\n",
        "print(\"Gensim version\")\n",
        "print (gensim.__version__)\n",
        "print(\"Pandas version\")\n",
        "print (pd.__version__)\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW09E2WTWYeC",
        "colab_type": "text"
      },
      "source": [
        "##Números randômicos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoJ7JNnEXIMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seed(datetime.datetime.now().second)\n",
        "\n",
        "random_numbers = [534, 424, 826, 310, 983]\n",
        "\n",
        "# for _ in range(5):\n",
        "# \tvalue = randint(0, 1000)\n",
        "# \trandom_numbers.append(value)\n",
        " \n",
        "print(random_numbers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJfURIvSgKUb",
        "colab_type": "text"
      },
      "source": [
        "## Tratamento do dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP_g5WxICVS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_corpus_for_docs(docs):\n",
        "    \"\"\"\n",
        "    Faz o tratamento da base e retorna o corpus, dicionário e query tratada\n",
        "    \"\"\"\n",
        "    # Download and import stopwords library\n",
        "    stopwds = stopwords.words('english')\n",
        "\n",
        "    # Split the documents into tokens.\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    for idx in range(len(docs)):\n",
        "        docs[idx] = str(docs[idx]).lower()  # Convert to lowercase.\n",
        "        docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
        "\n",
        "    # Remove stopwords.\n",
        "    docs = [[token for token in doc if token not in stopwds] for doc in docs]\n",
        "\n",
        "    # Remove rare and common tokens.\n",
        "    # Create a dictionary representation of the documents.\n",
        "    dictionary = Dictionary(docs)\n",
        "\n",
        "    # Bag-of-words representation of the documents.\n",
        "    corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
        "\n",
        "    return corpus, dictionary, docs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwYDsCa6kbCu",
        "colab_type": "text"
      },
      "source": [
        "## Executa LDA e retorna TOP documentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN6AK9bOkbjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top_documents(df, corpus, dictionary, query, num_topics, random_state):\n",
        "    \"\"\"\n",
        "    Retorna TOP 10 documentos da query.\n",
        "    \n",
        "    Recebe a base original, corpus, dicionário, query de busca, número de\n",
        "    tópicos e a semente do random.\n",
        "    \"\"\"\n",
        "    # Make a index to word dictionary.\n",
        "    temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "    id2word = dictionary.id2token\n",
        "\n",
        "    # Train LDA model.\n",
        "    model = LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=id2word,\n",
        "        alpha='auto',\n",
        "        eta='auto',\n",
        "        num_topics=num_topics,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    total_docs = {}\n",
        "    relevant_docs = {}\n",
        "\n",
        "    # Loop over all the documents to group the probability of each topic\n",
        "    for docID, doc in enumerate(corpus):\n",
        "        topics = model.get_document_topics(doc)\n",
        "        for topicID, topic in topics:\n",
        "            if not topicID in total_docs:\n",
        "                total_docs[topicID] = 0\n",
        "\n",
        "            if not topicID in relevant_docs:\n",
        "                relevant_docs[topicID] = 0\n",
        "\n",
        "            total_docs[topicID] += 1\n",
        "            relevant_docs[topicID] += int(df.iloc[docID, :]['label'] == 'yes')\n",
        "\n",
        "    return total_docs, relevant_docs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVXberDcktet",
        "colab_type": "text"
      },
      "source": [
        "## Combinações de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ASUZ1tQYMda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dados de teste: DBs, número de tópicos e sementes do random state,\n",
        "DATABASES = {'Hall': 'Defect prediction', 'Radjenovic': 'Defect prediction metrics', 'Kitchenham': 'Literature review', 'Wahono': 'Defect prediction'}\n",
        "NUM_TOPICS_FOR_TEST = range(10, 201, 10)\n",
        "FIXED_OPTIONS = [0, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5FQS9NUYYi3",
        "colab_type": "text"
      },
      "source": [
        "#Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCkxTatmOkyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for dbname, query in DATABASES.items():\n",
        "    path = 'https://github.com/fastread/src/raw/master/workspace/data/{}.csv'.format(dbname)\n",
        "\n",
        "    #Carregando dataset\n",
        "    df = pd.read_csv(path, header=0, encoding='latin-1')\n",
        "\n",
        "    base_docs = df['Document Title'] + ' ' + df['Abstract']\n",
        "\n",
        "    corpus, dictionary, docs = get_corpus_for_docs(base_docs)\n",
        "    tmp_corpus, tmp_dict, tmp_query = get_corpus_for_docs([query]) # query tem o mesmo preprocessamento da coleção\n",
        "    query = tmp_query[0]\n",
        "\n",
        "    for rand_seed in random_numbers:\n",
        "        total_docs = pd.DataFrame(columns=range(200))\n",
        "        relevant_docs = pd.DataFrame(columns=range(200))\n",
        "\n",
        "        for num_topics in NUM_TOPICS_FOR_TEST:\n",
        "            print(num_topics, dbname, rand_seed)\n",
        "            d, r = get_top_documents(df, corpus, dictionary, query, num_topics, rand_seed)\n",
        "            total_docs = total_docs.append(d, ignore_index=True)\n",
        "            relevant_docs = relevant_docs.append(r, ignore_index=True)\n",
        "\n",
        "        total_docs.index = NUM_TOPICS_FOR_TEST\n",
        "        relevant_docs.index = NUM_TOPICS_FOR_TEST\n",
        "\n",
        "        total_docs = total_docs.T\n",
        "        relevant_docs = relevant_docs.T\n",
        "\n",
        "        drive.mount('drive', force_remount=True)\n",
        "        total_docs.to_csv('drive/My Drive/Pureza Tópicos/{}_{}_{}.csv'.format('total_docs', dbname, rand_seed))\n",
        "        relevant_docs.to_csv('drive/My Drive/Pureza Tópicos/{}_{}_{}.csv'.format('relevant_docs', dbname, rand_seed))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}